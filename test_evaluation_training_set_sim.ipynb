{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a13cea1-2213-4988-a550-150fc18c3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import rmsd_predictor_evaluator\n",
    "from tqdm import tqdm\n",
    "from litschnet import LitSchNet\n",
    "from rmsd_predictor_evaluator import RMSDPredictorEvaluator\n",
    "from conf_ensemble_dataset_in_memory import ConfEnsembleDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2f3dd5-ccab-4a09-ac54-75828b481753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "split = 'random'\n",
    "dataset = 'pdbbind'\n",
    "iteration = 0\n",
    "with open(os.path.join(data_dir, f'ligand_{split}_splits', f'train_smiles_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    train_smiles = f.readlines()\n",
    "    train_smiles = [smiles.strip() for smiles in train_smiles]\n",
    "            \n",
    "with open(os.path.join(data_dir, f'ligand_{split}_splits', f'test_smiles_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    test_smiles = f.readlines()\n",
    "    test_smiles = [smiles.strip() for smiles in test_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8063c0-ff6a-47d2-bc55-d9d9852c4d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58d5b79-1683-4edc-9db0-682428deda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_chunks = [filename for filename in os.listdir(os.path.join(data_dir, 'processed')) if filename.startswith('pdbbind')]\n",
    "pdbbind_n_chunks = len(pdbbind_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a6420d-13bd-4866-b104-743428369ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['all', 'easy', 'hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39c3e95-fa37-4829-b5fc-fa163ce18bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:21<00:00, 20.26s/it]\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "\n",
    "for chunk_number in tqdm(range(pdbbind_n_chunks)) :\n",
    "\n",
    "    dataset = ConfEnsembleDataset(loaded_chunk=chunk_number,\n",
    "                                  smiles_list=test_smiles)\n",
    "    test_datasets.append(dataset)\n",
    "\n",
    "test_dataset = ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ed5a0f-461f-40e1-8f84-a4b708dc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rmsd_predictor_evaluator)\n",
    "RMSDPredictorEvaluator = rmsd_predictor_evaluator.RMSDPredictorEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97dbbe00-946d-4a83-876f-3f13258f5c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing training set fingerprints\n",
      "Evaluation already done for given experiment random_split_0_v2_pdbbind\n",
      "Loading existing results\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f'{split}_split_{iteration}_v2'\n",
    "if experiment_name in os.listdir('lightning_logs') :\n",
    "    checkpoint_name = os.listdir(os.path.join('lightning_logs', experiment_name, 'checkpoints'))[0]\n",
    "    checkpoint_path = os.path.join('lightning_logs', experiment_name, 'checkpoints', checkpoint_name)\n",
    "    litschnet = LitSchNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "\n",
    "    evaluation_name = experiment_name + '_pdbbind'\n",
    "    evaluator = RMSDPredictorEvaluator(model=litschnet, \n",
    "                                       evaluation_name=evaluation_name, \n",
    "                                       training_smiles=train_smiles)\n",
    "    evaluator.evaluate(test_dataset)\n",
    "    evaluator.evaluation_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c94bc-9cc0-4071-b57b-745224729e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba319512-2b49-40a9-a0a0-8f1cc1e7d2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6cc179e-d4e3-4653-a329-6bea7c250a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "split = 'scaffold'\n",
    "dataset = 'pdbbind'\n",
    "iteration = 0\n",
    "with open(os.path.join(data_dir, f'ligand_{split}_splits', f'train_smiles_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    train_smiles = f.readlines()\n",
    "    train_smiles = [smiles.strip() for smiles in train_smiles]\n",
    "            \n",
    "with open(os.path.join(data_dir, f'ligand_{split}_splits', f'test_smiles_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    test_smiles = f.readlines()\n",
    "    test_smiles = [smiles.strip() for smiles in test_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a820adb-a1b3-46ea-9b5d-3d27941c1ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6b2416-1c11-4a07-8528-f2ae6824fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_chunks = [filename for filename in os.listdir(os.path.join(data_dir, 'processed')) if filename.startswith('pdbbind')]\n",
    "pdbbind_n_chunks = len(pdbbind_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0245e09-318c-40fd-be99-83b62404f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['all', 'easy', 'hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe450ef2-ba4d-41a8-810a-23616462ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:22<00:00, 20.67s/it]\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "\n",
    "for chunk_number in tqdm(range(pdbbind_n_chunks)) :\n",
    "\n",
    "    dataset = ConfEnsembleDataset(loaded_chunk=chunk_number,\n",
    "                                  smiles_list=test_smiles)\n",
    "    test_datasets.append(dataset)\n",
    "\n",
    "test_dataset = ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94704833-65b7-4f8c-b73e-20b7cc6497ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import rmsd_predictor_evaluator\n",
    "importlib.reload(rmsd_predictor_evaluator)\n",
    "RMSDPredictorEvaluator = rmsd_predictor_evaluator.RMSDPredictorEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "778087a7-5e91-4950-b257-bcf6f230f988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing training set fingerprints\n",
      "Grouping data by smiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1091 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1091/1091 [01:00<00:00, 17.97it/s]\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f'{split}_split_{iteration}_v2'\n",
    "if experiment_name in os.listdir('lightning_logs') :\n",
    "    checkpoint_name = os.listdir(os.path.join('lightning_logs', experiment_name, 'checkpoints'))[0]\n",
    "    checkpoint_path = os.path.join('lightning_logs', experiment_name, 'checkpoints', checkpoint_name)\n",
    "    litschnet = LitSchNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "\n",
    "    evaluation_name = experiment_name + '_pdbbind'\n",
    "    evaluator = RMSDPredictorEvaluator(model=litschnet, \n",
    "                                       evaluation_name=evaluation_name, \n",
    "                                       training_smiles=train_smiles)\n",
    "    evaluator.evaluate(test_dataset, overwrite=True)\n",
    "    evaluator.evaluation_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5a6c3-21d4-4b18-a001-344caf94a49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73d57a-bbd4-4693-aaae-5a70ec5f0060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2398a68f-5f24-4edf-ac9a-c1cfbad294e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "split = 'protein_similarity'\n",
    "dataset = 'pdbbind'\n",
    "iteration = 0\n",
    "with open(os.path.join(data_dir, f'{split}_splits', f'train_pdb_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    train_pdbs = f.readlines()\n",
    "    train_pdbs = [pdb.strip() for pdb in train_pdbs]\n",
    "            \n",
    "with open(os.path.join(data_dir, f'{split}_splits', f'test_pdb_{split}_split_{iteration}.txt'), 'r') as f :\n",
    "    test_pdbs = f.readlines()\n",
    "    test_pdbs = [pdb.strip() for pdb in test_pdbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f833c0-aefd-43fd-9f8a-f58453f9d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "smiles_df = pd.read_csv('data/smiles_df.csv')\n",
    "train_smiles = smiles_df[smiles_df['id'].isin(train_pdbs)]['smiles'].values\n",
    "test_smiles = smiles_df[smiles_df['id'].isin(test_pdbs)]['smiles'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c7086d-7968-40a5-83e2-03bd62110a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "426a9724-d4c6-482d-b103-06ec1cb5237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_chunks = [filename for filename in os.listdir(os.path.join(data_dir, 'processed')) if filename.startswith('pdbbind')]\n",
    "pdbbind_n_chunks = len(pdbbind_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de111e8-eb80-477a-84b2-7fc5ae053d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['all', 'easy', 'hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feea5ce3-99f2-460e-8549-1ef6621188b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:49<00:00, 27.42s/it]\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "\n",
    "for chunk_number in tqdm(range(pdbbind_n_chunks)) :\n",
    "\n",
    "    dataset = ConfEnsembleDataset(loaded_chunk=chunk_number,\n",
    "                                  pdb_ids_list=test_pdbs)\n",
    "    test_datasets.append(dataset)\n",
    "\n",
    "test_dataset = ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e018d8b3-83d8-44d7-bea2-6086cbe8185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import rmsd_predictor_evaluator\n",
    "importlib.reload(rmsd_predictor_evaluator)\n",
    "RMSDPredictorEvaluator = rmsd_predictor_evaluator.RMSDPredictorEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4024dfb6-a339-4948-86ed-997cca5928d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing training set fingerprints\n",
      "Evaluation already done for given experiment protein_split_0_v2_pdbbind\n",
      "Loading existing results\n"
     ]
    }
   ],
   "source": [
    "split = 'protein'\n",
    "experiment_name = f'{split}_split_{iteration}_v2'\n",
    "if experiment_name in os.listdir('lightning_logs') :\n",
    "    checkpoint_name = os.listdir(os.path.join('lightning_logs', experiment_name, 'checkpoints'))[0]\n",
    "    checkpoint_path = os.path.join('lightning_logs', experiment_name, 'checkpoints', checkpoint_name)\n",
    "    litschnet = LitSchNet.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "\n",
    "    evaluation_name = experiment_name + '_pdbbind'\n",
    "    evaluator = RMSDPredictorEvaluator(model=litschnet, \n",
    "                                       evaluation_name=evaluation_name, \n",
    "                                       training_smiles=train_smiles)\n",
    "    evaluator.evaluate(test_dataset)\n",
    "    evaluator.evaluation_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbf368-dd64-40c8-9a27-74a78ac31095",
   "metadata": {},
   "source": [
    "# Produce EF figures across split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8595844c-24b8-4249-b1d2-8c421100d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benoit/anaconda3/envs/GeoMol/lib/python3.7/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "splits = ['random', 'scaffold', 'protein']\n",
    "datasets = ['pdbbind', 'platinum']\n",
    "for dataset in datasets :\n",
    "    df = pd.DataFrame()\n",
    "    for split in splits :\n",
    "        evaluation_name = f'{split}_split_0_{dataset}'\n",
    "        ef_df_path = os.path.join('results/',\n",
    "                                 evaluation_name,\n",
    "                                 'ef_df.csv')\n",
    "        ef_df = pd.read_csv(ef_df_path, index_col=0)\n",
    "        ef_df['ranker'] = ef_df['ranker'].replace({'model' : f'model_{split}'})\n",
    "        df = df.append(ef_df, ignore_index=True)\n",
    "    df = df.rename({'Enrichment factor' : 'Enrichment factor of the top 10% closest to bioactive'}, axis=1)\n",
    "\n",
    "    sns.lineplot(data=df, x='Fraction', y=f'Enrichment factor of the top 10% closest to bioactive', hue='ranker')\n",
    "    plt.title(f'Generated conformation ranking evaluation ({dataset})')\n",
    "    fig_path = os.path.join('figures/', \n",
    "                            f'efs_{dataset}.png')\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1cffae4-9ac1-4262-818f-3999dcefc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['random', 'scaffold', 'protein']\n",
    "df = pd.DataFrame()\n",
    "for split in splits :\n",
    "    evaluation_name = f'{split}_split_0_platinum'\n",
    "    ef_df_path = os.path.join('results/',\n",
    "                             evaluation_name,\n",
    "                             'ef_df.csv')\n",
    "    ef_df = pd.read_csv(ef_df_path, index_col=0)\n",
    "    ef_df['ranker'] = ef_df['ranker'].replace({'model' : f'model_{split}'})\n",
    "    df = df.append(ef_df, ignore_index=True)\n",
    "df = df.rename({'Enrichment factor' : 'Enrichment factor of the top 10% closest to bioactive'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5783304d-6ea2-4e21-bb97-f779b9d27e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x='Fraction', y=f'Enrichment factor of the top 10% closest to bioactive', hue='ranker')\n",
    "plt.title(f'Generated conformation ranking evaluation')\n",
    "fig_path = os.path.join('figures/', \n",
    "                        f'efs.png')\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4911bc-5f01-4c5a-a1f3-270386270411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0b343b2-7a30-4d4f-85d5-e1d615d74d02",
   "metadata": {},
   "source": [
    "# Produce rigid-ligand docking figures across split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d48992-3bd6-4e87-a1ff-c7a439a43869",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['random', 'scaffold', 'protein']\n",
    "df = pd.DataFrame()\n",
    "for split in splits :\n",
    "    evaluation_name = f'{split}_split_0_v2_pdbbind'\n",
    "    recall_df_path = os.path.join('results/',\n",
    "                             evaluation_name,\n",
    "                             'rigid_ligand_docking_recall_successful_only.csv')\n",
    "    recall_df = pd.read_csv(recall_df_path, index_col=0)\n",
    "    recall_df['ranker'] = recall_df['ranker'].replace({'model' : f'model_{split}'})\n",
    "    df = df.append(recall_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a0f3646-a78d-467a-9be5-ff92c2c93526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conformation rank</th>\n",
       "      <th>Recall</th>\n",
       "      <th>metric</th>\n",
       "      <th>ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075542</td>\n",
       "      <td>score</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.103964</td>\n",
       "      <td>score</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.142109</td>\n",
       "      <td>score</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>score</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.190726</td>\n",
       "      <td>score</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conformation rank    Recall metric        ranker\n",
       "0                  0  0.075542  score  model_random\n",
       "1                  1  0.103964  score  model_random\n",
       "2                  2  0.142109  score  model_random\n",
       "3                  3  0.167539  score  model_random\n",
       "4                  4  0.190726  score  model_random"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f930905d-3009-4e94-9e98-fb0be2fcc252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCDC</th>\n",
       "      <td>0.262278</td>\n",
       "      <td>0.016340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.316484</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_protein</th>\n",
       "      <td>0.332944</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_random</th>\n",
       "      <td>0.577412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_scaffold</th>\n",
       "      <td>0.402421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.206594</td>\n",
       "      <td>0.022923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.773970</td>\n",
       "      <td>0.004849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Recall          \n",
       "                    mean       std\n",
       "ranker                            \n",
       "CCDC            0.262278  0.016340\n",
       "energy          0.316484  0.007794\n",
       "model_protein   0.332944       NaN\n",
       "model_random    0.577412       NaN\n",
       "model_scaffold  0.402421       NaN\n",
       "random          0.206594  0.022923\n",
       "score           0.773970  0.004849"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Conformation rank'] == 19) & (df['metric'] == 'ligand_rmsd')].groupby('ranker').agg({'Recall' : ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d799b73-2b53-48ca-80e4-5a0543691c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['score', 'ligand_rmsd', 'overlay_rmsd', 'docking_power',\n",
       "       'correct_conf'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acb04b41-d72f-4afb-9a85-2dc6c8a0c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'ligand_rmsd'\n",
    "metric_df = df[df['metric'] == metric]\n",
    "sns.lineplot(data=metric_df, x='Conformation rank', y=f'Recall', hue='ranker')\n",
    "\n",
    "if metric == 'docking_power' :\n",
    "    title = 'Docking power'\n",
    "elif metric == 'ligand_rmsd' :\n",
    "    title = 'Retrieval of closest conformation to bioactive'\n",
    "else :\n",
    "    title = f'Retrieval of top {metric}'\n",
    "\n",
    "plt.title(title)\n",
    "fig_path = os.path.join('figures/', \n",
    "                        f'{metric}_rigid_docking.png')\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9b97f8d-cc13-44e3-86a0-832b2ee7ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'ligand_rmsd'\n",
    "metric_df = df[df['metric'] == metric]\n",
    "sns.lineplot(data=metric_df, x='Conformation rank', y=f'Recall', hue='ranker')\n",
    "\n",
    "if metric == 'docking_power' :\n",
    "    title = 'Docking power'\n",
    "elif metric == 'ligand_rmsd' :\n",
    "    title = 'Retrieval of closest conformation to bioactive'\n",
    "else :\n",
    "    title = f'Retrieval of top {metric}'\n",
    "\n",
    "plt.title(title)\n",
    "plt.xlim(0, 20)\n",
    "fig_path = os.path.join('figures/', \n",
    "                        f'{metric}_rigid_docking_truncated.png')\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "718a2e62-1964-40c3-a414-a3a4e022b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "flexible_docking_powers = {\n",
    "    'random' : 0.57,\n",
    "    'scaffold' : 0.48,\n",
    "    'protein' : 0.53\n",
    "}\n",
    "\n",
    "generation_powers = {\n",
    "    'random' : 0.76,\n",
    "    'scaffold' : 0.70,\n",
    "    'protein' : 0.79\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "962326ef-9357-4636-a7c8-8a09add8aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Conformation rank    Recall         metric        ranker\n",
      "1505                  5  0.587933  docking_power  model_random\n",
      "1617                 17  0.572529  docking_power        energy\n",
      "1701                  1  0.591142  docking_power         score\n",
      "1812                 12  0.575096  docking_power        random\n",
      "1916                 16  0.573813  docking_power          CCDC\n",
      "      Conformation rank    Recall         metric          ranker\n",
      "1504                  4  0.500000  docking_power  model_scaffold\n",
      "1607                  7  0.486284  docking_power          energy\n",
      "1700                  0  0.567332  docking_power           score\n",
      "1806                  6  0.495012  docking_power          random\n",
      "1906                  6  0.493766  docking_power            CCDC\n",
      "      Conformation rank    Recall         metric         ranker\n",
      "1507                  7  0.534722  docking_power  model_protein\n",
      "1608                  8  0.542659  docking_power         energy\n",
      "1700                  0  0.589286  docking_power          score\n",
      "1806                  6  0.534722  docking_power         random\n",
      "1907                  7  0.531746  docking_power           CCDC\n"
     ]
    }
   ],
   "source": [
    "splits = ['random', 'scaffold', 'protein']\n",
    "df = pd.DataFrame()\n",
    "for split in splits :\n",
    "    evaluation_name = f'{split}_split_0_v2_pdbbind'\n",
    "    recall_df_path = os.path.join('results/',\n",
    "                             evaluation_name,\n",
    "                             'rigid_ligand_docking_recall_all.csv')\n",
    "    recall_df = pd.read_csv(recall_df_path, index_col=0)\n",
    "    recall_df['ranker'] = recall_df['ranker'].replace({'model' : f'model_{split}'})\n",
    "    flexible_docking_power = flexible_docking_powers[split]\n",
    "    print(recall_df[(recall_df['Recall'] >= flexible_docking_power) \n",
    "              & (recall_df['metric'] == 'docking_power')].drop_duplicates(subset='ranker'))\n",
    "    df = df.append(recall_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7735308-d094-4d15-aeb6-1887fb4bb693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ranker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCDC</th>\n",
       "      <td>0.815619</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.815619</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_protein</th>\n",
       "      <td>0.825397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_random</th>\n",
       "      <td>0.822208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_scaffold</th>\n",
       "      <td>0.799252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.815619</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.815619</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Recall          \n",
       "                    mean       std\n",
       "ranker                            \n",
       "CCDC            0.815619  0.014264\n",
       "energy          0.815619  0.014264\n",
       "model_protein   0.825397       NaN\n",
       "model_random    0.822208       NaN\n",
       "model_scaffold  0.799252       NaN\n",
       "random          0.815619  0.014264\n",
       "score           0.815619  0.014264"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Conformation rank'] == 99) & (df['metric'] == 'docking_power')].groupby('ranker').agg({'Recall' : ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea243cd5-e458-43b0-bf3c-4703cd32f9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conformation rank</th>\n",
       "      <th>Recall</th>\n",
       "      <th>metric</th>\n",
       "      <th>ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>6</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>21</td>\n",
       "      <td>0.605905</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>2</td>\n",
       "      <td>0.618742</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>15</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>19</td>\n",
       "      <td>0.602696</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>CCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>9</td>\n",
       "      <td>0.604738</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_scaffold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>11</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Conformation rank    Recall         metric          ranker\n",
       "1506                  6  0.603338  docking_power    model_random\n",
       "1621                 21  0.605905  docking_power          energy\n",
       "1702                  2  0.618742  docking_power           score\n",
       "1815                 15  0.605263  docking_power          random\n",
       "1919                 19  0.602696  docking_power            CCDC\n",
       "4009                  9  0.604738  docking_power  model_scaffold\n",
       "6511                 11  0.608135  docking_power   model_protein"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Recall'] >= 0.60) & (df['metric'] == 'docking_power')].drop_duplicates(subset='ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "526bbace-c6bf-49df-8ae2-1bad9573b12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conformation rank</th>\n",
       "      <th>Recall</th>\n",
       "      <th>metric</th>\n",
       "      <th>ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>5</td>\n",
       "      <td>0.587933</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>17</td>\n",
       "      <td>0.572529</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>1</td>\n",
       "      <td>0.591142</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>12</td>\n",
       "      <td>0.575096</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>16</td>\n",
       "      <td>0.573813</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>CCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>8</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_scaffold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>9</td>\n",
       "      <td>0.573413</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Conformation rank    Recall         metric          ranker\n",
       "1505                  5  0.587933  docking_power    model_random\n",
       "1617                 17  0.572529  docking_power          energy\n",
       "1701                  1  0.591142  docking_power           score\n",
       "1812                 12  0.575096  docking_power          random\n",
       "1916                 16  0.573813  docking_power            CCDC\n",
       "4008                  8  0.586035  docking_power  model_scaffold\n",
       "6509                  9  0.573413  docking_power   model_protein"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Recall'] >= 0.57) & (df['metric'] == 'docking_power')].drop_duplicates(subset='ranker')# .groupby('ranker').agg({'Conformation rank' : ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4a71da9-b54d-4d0b-bf24-256670bcaf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conformation rank</th>\n",
       "      <th>Recall</th>\n",
       "      <th>metric</th>\n",
       "      <th>ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2</td>\n",
       "      <td>0.494865</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>9</td>\n",
       "      <td>0.486521</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>0</td>\n",
       "      <td>0.537227</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>7</td>\n",
       "      <td>0.489089</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>8</td>\n",
       "      <td>0.482028</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>CCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_scaffold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>5</td>\n",
       "      <td>0.502976</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Conformation rank    Recall         metric          ranker\n",
       "1502                  2  0.494865  docking_power    model_random\n",
       "1609                  9  0.486521  docking_power          energy\n",
       "1700                  0  0.537227  docking_power           score\n",
       "1807                  7  0.489089  docking_power          random\n",
       "1908                  8  0.482028  docking_power            CCDC\n",
       "4004                  4  0.500000  docking_power  model_scaffold\n",
       "6505                  5  0.502976  docking_power   model_protein"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Recall'] >= 0.48) & (df['metric'] == 'docking_power')].drop_duplicates(subset='ranker')# .groupby('ranker').agg({'Conformation rank' : ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db104db3-81d3-4614-bdce-e7a73ca6ba85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conformation rank</th>\n",
       "      <th>Recall</th>\n",
       "      <th>metric</th>\n",
       "      <th>ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>3</td>\n",
       "      <td>0.535302</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>13</td>\n",
       "      <td>0.534660</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>0</td>\n",
       "      <td>0.537227</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>9</td>\n",
       "      <td>0.533376</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>12</td>\n",
       "      <td>0.530809</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>CCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>6</td>\n",
       "      <td>0.549875</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_scaffold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>7</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>docking_power</td>\n",
       "      <td>model_protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Conformation rank    Recall         metric          ranker\n",
       "1503                  3  0.535302  docking_power    model_random\n",
       "1613                 13  0.534660  docking_power          energy\n",
       "1700                  0  0.537227  docking_power           score\n",
       "1809                  9  0.533376  docking_power          random\n",
       "1912                 12  0.530809  docking_power            CCDC\n",
       "4006                  6  0.549875  docking_power  model_scaffold\n",
       "6507                  7  0.534722  docking_power   model_protein"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Recall'] >= 0.53) & (df['metric'] == 'docking_power')].drop_duplicates(subset='ranker')# .groupby('ranker').agg({'Conformation rank' : ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eba82f-fa3b-4356-82b5-578744426057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bd80418-2f68-4f47-ba97-09dbd412df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'docking_power'\n",
    "metric_df = df[df['metric'] == metric]\n",
    "sns.lineplot(data=metric_df, x='Conformation rank', y=f'Recall', hue='ranker')\n",
    "\n",
    "if metric == 'docking_power' :\n",
    "    title = 'Docking power'\n",
    "elif metric == 'ligand_rmsd' :\n",
    "    title = 'Retrieval of closest conformation to bioactive'\n",
    "else :\n",
    "    title = f'Retrieval of top {metric}'\n",
    "\n",
    "plt.title(title)\n",
    "plt.ylim(0,1)\n",
    "fig_path = os.path.join('figures/', \n",
    "                        f'{metric}_rigid_docking.png')\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "029bf6d5-010b-4576-8fa2-cb28001f4029",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'docking_power'\n",
    "metric_df = df[df['metric'] == metric]\n",
    "sns.lineplot(data=metric_df, x='Conformation rank', y=f'Recall', hue='ranker')\n",
    "\n",
    "if metric == 'docking_power' :\n",
    "    title = 'Docking power'\n",
    "elif metric == 'ligand_rmsd' :\n",
    "    title = 'Retrieval of closest conformation to bioactive'\n",
    "else :\n",
    "    title = f'Retrieval of top {metric}'\n",
    "\n",
    "plt.title(title)\n",
    "plt.xlim(0, 20)\n",
    "fig_path = os.path.join('figures/', \n",
    "                        f'{metric}_rigid_docking_trucated.png')\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
